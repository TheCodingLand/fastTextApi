higher level approach 



model object : 

{ name = String,
 version = number, //this allows to store several versions of the models you have, 
 classified = Bool,
 config = config object }

config object : 
{ bias,
  ngrams,
  learningRate,
  epochs }


fasttext api :



/preload { "modelname" : String, "version" : Number } => 
	success 200: loaded model in memory
	error: 404 file not found
	error : 500 : "resource error" (out of memory) or "model file error"

/load {name:String, version:Number}
	

/loadedmodels { } : => { [model1, model2, model3...] } // lists model objects loaded in memory

/predict { "modelname : String", "version = Number", "text : String",  "nbofresults : Number"  } => { results : [ result : "String", confidence: "Number" ] } // if model is not preloaded, will attempt to load it 

/predictunsipervised { "modelname : String", "version (optional) = Number", "input : String",  "nbofresults : Number" } => { results : [ result : "String", confidence: "Number" ] }

/apply { "model", "data file" } => { model1, model2, model3} (one uage is splitting data into languages for example )

/train { "trainingdata", "model : model object" } => trainingdata is an array of objects: [{ text : String, category : String}, ]

/test { "modelname : String", trainingdata: String", version (optional) = Number, split_ratio: Number, confidence_threshold: Number }




Volumes : 

/trainingdata volume is where your data goes. there are upload mechanisms. store data as json object : 
[{ text : String, category : String}, ]
or
[{ text : String }, ]
for unclassified



All models created by the /train request goes into the models volume 

models : 
/models/{name}/{version}/model.ftz

Models generated by apply will be stored like this :
/models/{name}{classification}/

